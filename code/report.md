## ARC提示词工程实验报告

### 一、实验背景与目标

- 简述本实验的目标：利用提示词工程让大语言模型（LLM）解决 ARC（Abstraction and Reasoning Corpus）推理任务。
- 概述 ARC 任务特点：输入输出网格变换、抽象规则、泛化与推理难度。
- 明确本实验的核心问题：如何通过提示词设计引导模型发现隐藏规律并输出正确结果。

### 二、实验环境与工具

- **模型及 API**：如 DeepSeek-V3.2 (chat 模式)，temperature=1.0，max_tokens=8k。
- **运行环境**：Python 3.9，使用官方 API。
- **文件说明**：
  - `template.py`：包含 `construct_prompt()` 与 `parse_output()` 函数。
  - `report.pdf`：即本报告。

### 三、提示词策略设计思路

#### 3.1 基础提示词设计（Baseline）

- 系统提示词设计逻辑

  1. 角色设定

     将模型定义为“ARC谜题专家”，强调其在“模式识别”和“逻辑推理”方面的能力。

  2. 任务目标明确化

     分析训练样本的变换模式

     识别所有样本中一致的规则

     将规则精确地应用到测试输入上

  3. 行为约束

     请系统化和精确地进行分析。

- 用户提示词设计逻辑

  1. 结构化分步设计

     明确解题过程（**观察 → 模式发现 → 规则验证 → 应用 → 输出**）。

  2. 强化观察阶段

     要求模型从**网格维度、数值分布、非零元素位置、空间结构**等角度全面观察。

  3. 指导模式发现

     明确列出可供思考的变换类型（**平移、旋转、反射、颜色变化、对称性、数学关系**等）。

  4. 规则验证

     强制模型验证规则在所有样本上的一致性，鼓励其形成“通用规则”而非单例映射。

  5. 测试应用与输出

     要求模型系统化应用已验证规则，并展示推理过程。

     最后规定输出格式必须为 `[[...], [...]]` 的 Python 二维列表，并加上“最终输出：”标识。

     这一格式约束减少了解析错误，有助于程序自动提取结果。

- 问题与不足

  1. **无法应对复杂问题**，例如使用多个操作对矩阵进行变化。
  2. **泛化能力有限**，缺乏层级推理机制。

- 结果

```
Epoch 1 Results:
  Successfully processed: 20/20 samples
  Failed samples: 0
  Correct predictions: 15/20
  Accuracy (on completed samples): 75.00%

==================================================
=== Final Results ===
Total samples in dataset: 20
Final Accuracy: 75.00%
```

#### 3.2 尝试一：丰富ARC操作步骤

- 引入多步骤构建与验证机制

  优先单步规则：**先尝试最简单的单步操作**（如旋转或颜色映射），验证是否匹配所有训练样本。
  迭代多步扩展：如果单步失败，逐步添加第二步、第三步操作**（最多三步）**，以**模拟复合变换。**
  限制步数：最多三步，避免过度复杂化，确保模型遵循**奥卡姆剃刀原则**（优先简单解释）。
  验证强化：在规则验证阶段，明确要求展示每步中间结果，并迭代调整规则。

- 核心更改部分

```markdown
### 步骤2：模式发现
通过以下方面识别变换规则。**优先尝试单步规则，如果单步无法一致匹配所有样本，则逐步添加第二步、第三步操作（最多三步组合）**：
- 移动模式（平移、旋转、反射、缩放）
- 颜色/数值变换
- 元素的分组或分割
- 对称操作
- 数学关系
- 基于区域的操作（角落、边缘、中心）
- 复制或删除模式

**规则构建原则**：
- 先假设单步规则（如“所有输入元素顺时针旋转90度”），并在步骤3验证。
- 如果单步规则无法匹配所有训练样本，则尝试两步组合（如“先提取红色元素，再旋转90度”）。
- 如果两步仍不匹配，则尝试三步组合（如“先复制元素到四个角落，再翻转，再填充颜色”）。
- 最多使用三步操作；优先最简单的解释（奥卡姆剃刀原则）。
- 清晰描述每步操作的顺序和细节。
```

- 运行结果

  与Baseline相比下降10%

```
Epoch 1 Results:
  Successfully processed: 20/20 samples
  Failed samples: 0
  Correct predictions: 13/20
  Accuracy (on completed samples): 65.00%

==================================================
=== Final Results ===
Total samples in dataset: 20
Final Accuracy: 65.00%
```

- 结果分析
  1. prompt长度、复杂性增加。可能导致模型在处理时注意力分散或token超限。
  2. 在temperature=1.0的设置下，复杂prompt易产生“创意变异”。
  3. 模型推理链负担加重。推理过程消耗更多计算资源。
  4. 多步验证增加输出变异性。

#### 3.3 尝试二：丰富ARC操作类型

- 增强操作类型的完整性和细化模式分析步骤

  在Baseline中，我们实现了一个基础的ARC谜题求解提示词框架，但通过对失败案例的分析发现，模型在某些特定的ARC操作类型上的识别能力不足。模型容易混淆不同的操作类型，导致规则提取失败。

  根据ARC的操作分类学研究[，**ARC任务涉及的操作远超过之前的7种基础类型。**

  因此，本次实验（尝试二）的目标是通过增强操作类型的完整性和细化模式分析步骤，提高模型在多样化ARC任务上的表现。

- 核心更改部分

```markdown
**同时，初步识别这个任务可能涉及的操作类型（可多选）：**

**基础操作：**
- [ ] 简单颜色/数值映射 - 将一种颜色变成另一种颜色
- [ ] 平移(Translation) - 元素在网格中移动位置
- [ ] 旋转(Rotation) - 元素或整个网格旋转(90°/180°/270°)
- [ ] 翻转/反射(Reflection) - 沿水平/竖直/对角线翻转
- [ ] 缩放(Scaling) - 放大或缩小元素或整个网格

**对象和结构操作：**
- [ ] 对象提取/分离 - 提取特定颜色或形状的对象
- [ ] 连通分量识别 - 找出相邻的同色元素组作为一个整体
- [ ] 边界/框架操作 - 添加、删除或检测边框/轮廓
- [ ] 元素的分组或分割 - 根据位置或属性分组

**模式和重复操作：**
- [ ] 重复/平铺(Repetition) - 小图案重复排列
- [ ] 模式检测 - 识别重复出现的图案或周期性结构
- [ ] 复制模式 - 将模式从一个位置复制到另一个位置

**填充和区域操作：**
- [ ] 填充/清空(Fill/Erase) - 用特定颜色填充或清空区域
- [ ] 洪泛填充(Flood Fill) - 填充连续的同色区域
- [ ] 基于区域的操作 - 针对角落、边缘、中心等特定区域的操作
- [ ] 网格划分 - 将网格分成块或象限分别处理

**高阶逻辑操作：**
- [ ] 对称操作 - 基于对称性的变换
- [ ] 条件规则 - 根据条件应用不同的变换(如：如果在边界→变红)
- [ ] 逻辑AND/OR/NOT - 基于多个条件的布尔操作
- [ ] 数学关系 - 基于计数、距离、大小等数值关系

**尺寸和维度操作：**
- [ ] 网格扩展/扩大 - 增大网格尺寸
- [ ] 网格裁剪/缩小 - 减小网格尺寸
- [ ] 行/列重复 - 重复特定的行或列
- [ ] 行/列删除 - 删除特定的行或列
- [ ] 投影操作 - 将二维信息压缩到一维(横向/纵向投影)

**比较和关系操作：**
- [ ] 计数操作 - 基于元素数量的变换
- [ ] 相对位置操作 - 基于相对位置(左边/右边/上方/下方)
- [ ] 相似性检测 - 找相似或相同的元素
- [ ] 最大值/最小值提取 - 提取最大或最小的对象
```

- 运行结果

  与Baseline相比下降5%。

```
Epoch 1 Results:
  Successfully processed: 20/20 samples
  Failed samples: 0
  Correct predictions: 14/20
  Accuracy (on completed samples): 70.00%

==================================================
=== Final Results ===
Total samples in dataset: 20
Final Accuracy: 70.00%
```

- 结果分析
  1. 认识负担过高。LLM在选择操作类型时产生更多不确定性，导致对规则的错误识别。
  2. 过度指导。对于简单的颜色映射问题，模型浪费大量Token在"对象分析"、"模式检测"等不相关的维度上。
  3. 模型不匹配。一些简单任务只涉及1-2种操作。模型被迫思考不相关的操作，产生虚假的操作识别。

#### 3.4 尝试三：代码自适应

- 自适应动态提示词生成系统

  尝试一，二的失败教训表明，**一刀切的提示词策略不适合多样化的ARC任务**。在temperature=1.0的高随机性环境下，过度复杂的指导反而会降低模型性能。

  基于这一认识，尝试三采用了**自适应动态提示词生成系统**，其核心理念是：

  > **不同任务应该获得不同的提示词，复杂度越高的任务获得越详细的指导，简单任务则保持简洁。**

  实现这一目标的关键是引入**任务特征分析模块**，能够自动识别任务的复杂度等级和操作类别。

- 实现方式

```
输入任务d
    ↓
[任务特征分析模块]
    ↓
analyze_task_characteristics(d)
    ├─ 计算7个分析维度
    ├─ 得到complexity_level
    └─ 得到operation_category
    ↓
[动态操作选择模块]
    ↓
select_relevant_operations(characteristics)
    ├─ 从操作库选择相关操作
    └─ 得到selected_operations列表
    ↓
[提示词生成模块]
    ↓
construct_prompt(d)
    ├─ if complexity_level == 'simple' → construct_simple_prompt()
    ├─ elif complexity_level == 'moderate' → construct_moderate_prompt()
    └─ else → construct_complex_prompt()
    ↓
生成messages
    ↓
[LLM调用]
    ↓
[输出解析 - parse_output()]
    ↓
提取最终网格
```

- 结果

  与Baseline相比下降15%。

```
Epoch 1 Results:
  Successfully processed: 20/20 samples
  Failed samples: 0
  Correct predictions: 14/20
  Accuracy (on completed samples): 70.00%

==================================================
=== Final Results ===
Total samples in dataset: 20
Final Accuracy: 70.00%
```

- 结果分析
  1. 使用代码进行特征分析，不太符合完全依赖提示词让大模型进行预测的要求（利用**代码分析任务复杂度**选取合适的提示词）。**因此后续在这个方法上没有过多研究。**不过这提供了一个思路，让大模型先自己试着分析任务复杂度，然后动态地采取相应的策略。
  2. 任务复杂度计算公式不合理。
  3. 问题分类后导致模型过度自信。

#### 3.5 尝试四：多角度适应

- 在前三次尝试的基础上，尝试四回归到**提示词优化**的路线，但采用了新的策略思路：

  1. **多角度观察框架** - 从全局、局部、分块三个角度观察矩阵，而非单一角度
  2. **单步规则强制约束** - 显式要求提示词中多次出现"单一变换规则"，防止LLM构造过于复杂的规则
  3. **详细的验证步骤** - 在步骤3中要求逐样本验证，确保规则一致性

- 核心更改部分

  **设计逻辑**：

  传统观察方式只从一个角度看（整体或局部），容易遗漏关键信息。多角度观察能覆盖更全面的特征。

  **三个观察维度**：

  | 维度         | 关注点                                      | 作用                       |
  | ------------ | ------------------------------------------- | -------------------------- |
  | **全局视图** | 整体尺寸、非零分布、颜色总体变化            | 理解整体变换方向           |
  | **局部细节** | 具体位置、相邻元素、细微模式                | 发现精细规则               |
  | **分块观察** | 将矩阵分块(如2×2)、每块内形状、块间对应关系 | 识别周期性、重复性、对称性 |

  提示词表述举例：

```
# 步骤1中的关键文本
- **全局视图**：整体网格维度、非零值分布模式、颜色整体变换
- **局部细节**：所有非零值的位置、相邻元素交互、颜色模式
- **分块观察**：分成小块、分析每块内形状、块间对应关系
```

- 结果

```
Epoch 1 Results:
  Successfully processed: 20/20 samples
  Failed samples: 0
  Correct predictions: 14/20
  Accuracy (on completed samples): 70.00%

==================================================
=== Final Results ===
Total samples in dataset: 20
Final Accuracy: 70.00%
```

- 结果分析
  1. 多角度观察→更多决策点→出错概率增加。
  2. 更强的约束不一定有更好的准确性。

### 四、输出解析策略（parse_output）

提取二维列表

不依赖一种方法，而是使用了一个**“瀑布式”或“降级（Fallback）”策略**来提取二维列表。

按照从最可靠到最不可靠的顺序尝试以下4种策略，一旦某个策略成功解析并验证了网格，它会立即返回结果，不再尝试后续策略。

1. 查找“最终输出”标记 (最优先)。这是最理想、最准确的策略，它**完全依赖于提示词（Prompt）在 阶段5 中设定的规则。**
2. 查找最后一个Python列表 (二级备选)。
3. 查找其他关键词 (三级备选)。
4. 查找原始数字矩阵 (最后手段)。

### 五、实验结果与分析

#### 5.1 在验证集上的表现

| 实验编号 | 提示词策略       | 准确率（val.jsonl） | 备注                                                         |
| -------- | ---------------- | ------------------- | ------------------------------------------------------------ |
| 1        | 基础版           | 0.75                | 结构简单，但是效果好。<br />考虑到真实数据会有更难的解题策略，<br />还需要进一步优化。 |
| 2        | 尝试一（多步骤） | 0.65                | 下降10%。<br />prompt长度、复杂性增加。                      |
| 3        | 尝试二（多类型） | 0.70                | 下降10%。<br />认识负担过高。过度指导。                      |
| 4        | 代码自适应       | 0.7                 | 下降5%。<br />代码分析任务复杂度后选择合适的提示词。         |
| 5        | 多角度适应       | 0.7                 | 下降5%。<br />多角度观察容易带来更高的错误率。               |

#### 5.2 定性分析

- 对比不同策略在“规则抽象”“输出格式”“稳定性”上的差异。
- 可附若干示例任务截图或表格，展示预测与真实输出对比。

### 六、总结与反思

提示词工程并不像传统做项目一样，优先考虑跑通程序，而是在提示词的优化上。选取合适的优化可以直接提高准确性。

优化方面有时候并不是写得越详细越好。这需要一种微妙的平衡。既要提供足够的**上下文（Context）**，又要避免引入认知的**噪音（Noise）**。这不再是关于词语的数量，而是关于词语的质量、结构和安放的位置。

在实践中，这需要：

1. **精确性高于冗长性：** 优化的目标通常不是添加更多细节，而是找到那个*最关键*的细节。例如，与其写“确保答案不要太长，要抓住要点”，不如用“简洁明了”这个指令来得更直接、更强大。
2. **结构化引导：** 提示词的格式本身就是一种指令。使用清晰的结构元素（如标题 `##`、数字步骤、甚至XML标签 `<示例>`）来引导模型的注意力，远比一大段非结构化的文本更有效。将一个复杂任务分解为一系列明确的简单步骤（就像你的ARC提示词那样）就是最好的例子。
3. **理解“留白”：** 同样重要的是你*没有*说什么。添加太多不相关（尽管正确）的信息会“污染”上下文窗口，稀释主要指令，导致模型抓住一个不重要的细节。优化的艺术在于*只*提供完成任务所必需的信息。
4. **迭代与假设检验：** 因为我们面对的是一个概率系统，提示工程更像是一门实验科学。这个过程包括：提出假设（例如，“我认为模型失败是因为它误解了输出格式”），然后通过调整提示词（例如，只增加一个“少样本”示例）来进行实验，最后分析输出结果。

本质上，优化不是从一开始就写出一个完美、详尽的规范。而是通过**迭代**，去发现那一套最精简的指令、示例和结构线索，从而使*期望的输出*成为模型最*可能*生成的输出。